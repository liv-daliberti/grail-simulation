{
  "model": "gpt-4o",
  "dataset": "/n/fs/similarity/grail-simulation/data/cleaned_grail",
  "split": "validation",
  "n_total": 2419,
  "n_eligible": 2419,
  "accuracy_overall": 0.2629185613890037,
  "parsed_rate": 1.0,
  "format_rate": 1.0,
  "position_stats": {
    "1": {
      "n_seen": 0,
      "n_eligible": 0,
      "correct": 0,
      "accuracy": 0.0,
      "parsed_rate": 0.0,
      "format_rate": 0.0
    },
    "2": {
      "n_seen": 0,
      "n_eligible": 0,
      "correct": 0,
      "accuracy": 0.0,
      "parsed_rate": 0.0,
      "format_rate": 0.0
    },
    "3": {
      "n_seen": 0,
      "n_eligible": 0,
      "correct": 0,
      "accuracy": 0.0,
      "parsed_rate": 0.0,
      "format_rate": 0.0
    },
    "4": {
      "n_seen": 0,
      "n_eligible": 0,
      "correct": 0,
      "accuracy": 0.0,
      "parsed_rate": 0.0,
      "format_rate": 0.0
    },
    "5+": {
      "n_seen": 0,
      "n_eligible": 0,
      "correct": 0,
      "accuracy": 0.0,
      "parsed_rate": 0.0,
      "format_rate": 0.0
    },
    "unknown": {
      "n_seen": 2419,
      "n_eligible": 2419,
      "correct": 636,
      "accuracy": 0.2629185613890037,
      "parsed_rate": 0.0,
      "format_rate": 0.0
    }
  },
  "by_n_options": {
    "hist_seen": {
      "1": 0,
      "2": 232,
      "3": 102,
      "4": 1785,
      "5+": 300
    },
    "hist_eligible": {
      "1": 0,
      "2": 232,
      "3": 102,
      "4": 1785,
      "5+": 300
    },
    "hist_correct": {
      "1": 0,
      "2": 82,
      "3": 33,
      "4": 464,
      "5+": 57
    },
    "accuracy": {
      "1": 0.0,
      "2": 0.35344827586206895,
      "3": 0.3235294117647059,
      "4": 0.25994397759103643,
      "5+": 0.19
    },
    "parsed_rate": {
      "1": 0.0,
      "2": 1.0,
      "3": 1.0,
      "4": 1.0,
      "5+": 1.0
    },
    "format_rate": {
      "1": 0.0,
      "2": 1.0,
      "3": 1.0,
      "4": 1.0,
      "5+": 1.0
    }
  },
  "split_single_vs_multi": {
    "n_single": 0,
    "n_multi": 2419,
    "eligible_single": 0,
    "eligible_multi": 2419,
    "accuracy_single": 0.0,
    "accuracy_multi": 0.2629185613890037,
    "parsed_rate_multi": 1.0,
    "format_rate_multi": 1.0
  },
  "group_metrics": {
    "by_issue": {
      "gun_control": {
        "n_seen": 548,
        "n_eligible": 548,
        "correct": 143,
        "accuracy": 0.26094890510948904,
        "parsed_rate": 1.0,
        "format_rate": 1.0
      },
      "minimum_wage": {
        "n_seen": 1871,
        "n_eligible": 1871,
        "correct": 493,
        "accuracy": 0.26349545697487975,
        "parsed_rate": 1.0,
        "format_rate": 1.0
      }
    },
    "by_participant_study": {
      "study1": {
        "n_seen": 548,
        "n_eligible": 548,
        "correct": 143,
        "accuracy": 0.26094890510948904,
        "parsed_rate": 1.0,
        "format_rate": 1.0
      },
      "study2": {
        "n_seen": 671,
        "n_eligible": 671,
        "correct": 192,
        "accuracy": 0.28614008941877794,
        "parsed_rate": 1.0,
        "format_rate": 1.0
      },
      "study3": {
        "n_seen": 1200,
        "n_eligible": 1200,
        "correct": 301,
        "accuracy": 0.25083333333333335,
        "parsed_rate": 1.0,
        "format_rate": 1.0
      }
    }
  },
  "filters": {
    "issues": [],
    "studies": []
  },
  "gold_index_distribution": {
    "1": 837,
    "2": 632,
    "3": 357,
    "4": 293,
    "5": 300
  },
  "baseline_most_frequent_gold_index": {
    "top_index": 1,
    "count": 837,
    "accuracy": 0.34601074824307565
  },
  "random_baseline_expected_accuracy": 0.27128978916907814,
  "notes": "Accuracy computed over eligible rows (gold_index>0). Buckets: 1..4, 5+, unknown."
}